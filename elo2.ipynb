{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will take our previous Elo system for tennis players and add playing surface as a parameter. There are a few ways in which surface has been taken into account.\n",
    "\n",
    "1. (Surface-only) treat each surface as a different sport altogether, so that each player has three ratings that don't interact with one another.\n",
    "2. (Weighted average) take the surface-specific ratings in item 1 above and the all-surfaces ratings developed in our previous post, then take a weighted average of them, minimizing the log-loss error.\n",
    "3. (Surface-dependent K-factor) According to the surface being played on, update each player's surface-specific rating according to a different K-factor and take the win probability from the corresponding surface-specific ratings.\n",
    "\n",
    "The first and second are implemented by Jeff Sackmann, the tennis data god, where the weighted average is the actual average. (Actually on his website, he averages the raw Elo ratings themselves, but that's fairly similar---though not identical---to what I described.) The third is the idea introduced in this post, which seems fairly natural to me and perhaps a little less ad-hoc than taking the average between surface-only and surface-agnostic ratings. So let's explain how the surface-dependent K-factor (SDKF) model works.\n",
    "\n",
    "\n",
    "## SDKF model\n",
    "\n",
    "Define $$\\sigma(x) = \\exp(x) / (\\exp(x) + 1),$$ the logistic function. If player one (p1) has rating $x$ and player two (p2) has rating $y$, the probability that p1 wins is given by $\\sigma(x-y)$. Suppose $w=1$ if p1 wins and $w=0$ if p1 loses. After the match, the ratings are updated with the rule $$x \\mapsto x + (-1)^{w+1} K(n_1)\\sigma((-1)^w(x-y)),\\quad y \\mapsto y+(-1)^w K(n_2)\\sigma((-1)^w (x-y)),$$ where $K$ is a function of the number of matches played by p1 ($n_1$) and the number of matches played by p2 ($n_2$). The function $K$ is of the form $$K(n) = \\frac{a}{(b + n)^c}.$$\n",
    "\n",
    "To define surface-specific ratings, we can do the following. Let $A$ be a $3\\times 3$ matrix. We map surfaces to indices: index 1 refers to clay, 2 to grass, 3 to hard. Now let $\\vec{x},\\vec{y}\\in \\mathbb{R}^3$ be the ratings of p1 and p2, respectively. Specifically, $$\\vec{x} = (x_1,x_2,x_3)$$ and $x_1$ is the p1 clay rating, $x_2$ is the p1 grass rating, and so on. Define $\\sigma(\\vec{x}) = (\\sigma(x_1),\\sigma(x_2),\\sigma(x_3))$. If $a_{ij}$ is the $(i,j)$ entry of $A$, then we make the following change to the update rule: $$\\vec{x} \\mapsto \\vec{x} + (-1)^{w+1}K(n_1)A\\sigma((-1)^w(\\vec{x}-\\vec{y})), \\quad \\vec{y} \\mapsto \\vec{y} + (-1)^w K(n_2)A\\sigma((-1)^w(\\vec{x}-\\vec{y})).$$\n",
    "\n",
    "The matrix $A$ consists of the speed with which to update each of the three ratings, given the surface being played on. For example, if the match is being played on grass, we intuit that the result shouldn't have a large effect on the players' clay rating, but it should have a large effect on the players' grass rating. On the other hand, if the match is being played on hard, we might think that it should have an equal effect on the players' grass and clay ratings.\n",
    "\n",
    "Finally, let's determine the win probability and the interpretation of the matrix $A$. If $$\\vec{s}=\\begin{cases} \\vec{e}_1 &\\quad \\text{ if clay} \\\\ \\vec{e}_2 &\\quad \\text{ if grass} \\\\ \\vec{e}_3 &\\quad \\text{ if hard} \\end{cases}$$ is the vector denoting surface being played on, then the win probability of p1 is $$\\sigma(\\vec{x}-\\vec{y})\\cdot \\vec{s}.$$ This indicates that **$a_{ij}$ is the update speed for the players' surface $i$ rating if the playing surface is $j$**.\n",
    "\n",
    "### Special cases\n",
    "It is instructive to examine special cases of $A$.\n",
    "1. If $A$ is the identity matrix, then no surface affects any other surface, and all the update coefficients are equal. So this would be equivalent to treating each surface as a different sport altogether (Surface-only ratings).\n",
    "2. If $A$ is the all-ones matrix, then all surfaces are treated equally. This results in surface-agnostic ratings, which is the classical setting.\n",
    "\n",
    "Based on these two extremes, we expect an effective $A$ to have heavy diagonal entries but nonzero off-diagonal entries, all positive. For our $K$, we take $a,b,c$ to be $$(a,b,c) = (0.47891635, 4.0213623 , 0.25232273)$$ based on training data from 1980 to 2014, from the previous post. Then we initialize the entries of $A$ to be uniform random numbers between 0 and 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(5192020) # today's date!\n",
    "\n",
    "def sigmoid(z):\n",
    "    '''The sigmoid function.'''\n",
    "    return np.where(z >= 0, \n",
    "                    1 / (1 + np.exp(-z)), \n",
    "                    np.exp(z) / (1 + np.exp(z)))\n",
    "\n",
    "class Elo_sdkf:\n",
    "    \n",
    "    def __init__(self, start_year, end_year, num_models, \n",
    "                 k_param = np.array([0.47891635, 4.0213623 , 0.25232273]),\n",
    "                 lower = np.zeros(9), upper = np.ones(9) * 1.5):\n",
    "        \n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "        self.num_models = num_models\n",
    "        \n",
    "        self.k_params = np.multiply(np.ones((num_models, 3)), k_param)\n",
    "        self.a_params = np.multiply(np.random.random((num_models, 9)), upper - lower) + lower\n",
    "        \n",
    "        self.data = []\n",
    "        for i in range(start_year, end_year + 1):\n",
    "            self.data.append(pd.read_csv('./atp/atp_matches_' + str(i) + '.csv'))\n",
    "        \n",
    "        # collect all the player names\n",
    "        self.players = {player for player in self.data[0]['winner_name']}\n",
    "        self.players = self.players.union({player for player in self.data[0]['loser_name']})\n",
    "        for i in range(1, end_year - start_year + 1):\n",
    "            self.players = self.players.union({player for player in self.data[i]['winner_name']})\n",
    "            self.players = self.players.union({player for player in self.data[i]['loser_name']})            \n",
    "        \n",
    "        # ratings are of the form (n, r)\n",
    "        # where n is the number of matches the player has played\n",
    "        # and r is their rating.\n",
    "        self.ratings = {player: (0, np.ones((num_models,3))) for player in self.players}\n",
    "        self.select_ratings = {player: (0,1.0) for player in self.players}\n",
    "        \n",
    "        col_names = ['a'+str(i) for i in range(1,10)]\n",
    "        self.params_data = pd.DataFrame({a : self.a_params[:,i] for (a,i) in zip(col_names, range(9))})\n",
    "        self.params_data['k1'] = self.k_params[:,0]\n",
    "        self.params_data['k2'] = self.k_params[:,1]\n",
    "        self.params_data['k3'] = self.k_params[:,2]\n",
    "        self.params_data['ll'] = np.zeros(num_models)\n",
    "        self.params_data['wp'] = np.zeros(num_models)\n",
    "        self.params_data['bs'] = np.zeros(num_models)\n",
    "        \n",
    "    def get_params(self):\n",
    "        return self.k_params.copy(), self.a_params.copy()\n",
    "    \n",
    "    def set_params(self, k_ps, a_ps):\n",
    "        self.k_params, self.a_params = k_ps, a_ps\n",
    "        \n",
    "    def get_params_data(self):\n",
    "        return self.params_data.copy()\n",
    "    \n",
    "    def k(self, n, ps):\n",
    "        '''returns the vector K-factor, which dictates how sensitive ratings are\n",
    "        to an individual match and depends on the number of matches played.'''\n",
    "        return np.multiply(ps[:,0], \n",
    "                           np.power(ps[:,1] + n, -ps[:,2])\n",
    "                          )\n",
    "    \n",
    "    \n",
    "    def update_one(self, x, y, n1, n2, k_params, a_params, s):\n",
    "        '''this function updates one match. 'x','y' are the ratings of\n",
    "        the winner and loser respectively, 'n1','n2' are the number of matches\n",
    "        that the winner and loser have played respectively. Returns the\n",
    "        prior probability that the winner wins, and the values to update \n",
    "        the ratings by. '''\n",
    "        z = np.multiply(np.dot(a_params.reshape((len(a_params),3,3)), s), sigmoid(y-x))\n",
    "        z1 = z[:,0]\n",
    "        z2 = z[:,1]\n",
    "        z3 = z[:,2]\n",
    "        u1 = np.multiply(self.k(n1, k_params), z1)\n",
    "        u2 = np.multiply(self.k(n1, k_params), z2)\n",
    "        u3 = np.multiply(self.k(n1, k_params), z3)\n",
    "        v1 = -np.multiply(self.k(n2, k_params), z1)\n",
    "        v2 = -np.multiply(self.k(n2, k_params), z2)\n",
    "        v3 = -np.multiply(self.k(n2, k_params), z3)\n",
    "        \n",
    "        u = np.transpose(np.array([u1,u2,u3]))\n",
    "        v = np.transpose(np.array([v1,v2,v3]))\n",
    "        prob = np.dot(sigmoid(x-y), s)\n",
    "        return(prob, u, v)\n",
    "    \n",
    "    def update_all_ratings(self, year):\n",
    "        '''update all the ratings at once. '''\n",
    "        # first reset the ratings.\n",
    "        self.ratings = {player: (0, np.ones((self.num_models,3))) \n",
    "                            for player in self.players}\n",
    "        \n",
    "        ll = np.zeros(self.num_models)\n",
    "        wp = np.zeros(self.num_models)\n",
    "        bs = np.zeros(self.num_models)\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            for j, row in self.data[i].iterrows():\n",
    "                \n",
    "                winner = row['winner_name']\n",
    "                loser = row['loser_name']\n",
    "                surface = row['surface']\n",
    "                if surface == 'Clay':\n",
    "                    s = np.array([1,0,0])\n",
    "                elif surface == 'Hard':\n",
    "                    s = np.array([0,0,1])\n",
    "                else: # Carpet gets classified as Grass.\n",
    "                    s = np.array([0,1,0])\n",
    "                \n",
    "                # get ratings.\n",
    "                wnm, wrating = self.ratings[winner]\n",
    "                lnm, lrating = self.ratings[loser]\n",
    "                \n",
    "                # update.\n",
    "                prob_vec, u1, u2 = self.update_one(wrating, lrating, wnm, lnm, \n",
    "                                                   self.k_params, self.a_params, s)\n",
    "                self.ratings[winner] = wnm + 1, wrating + u1\n",
    "                self.ratings[loser] = lnm + 1, lrating + u2\n",
    "                \n",
    "                # compute log-loss error or win prediction percentage.\n",
    "                if(i + self.start_year >= year):\n",
    "                    ll -= np.log(prob_vec)\n",
    "                    wp += (prob_vec > 0.5).astype(float)\n",
    "                    bs += np.power(1-prob_vec, 2)\n",
    "        \n",
    "        # figure out what to divide cost by.\n",
    "        num_rows = 0\n",
    "        for i in range(min(len(self.data), self.end_year + 1 - year)):\n",
    "            num_rows += len(self.data[year - self.start_year - 1 + i])\n",
    "\n",
    "        self.params_data['ll'] = ll / num_rows\n",
    "        self.params_data['wp'] = wp / num_rows\n",
    "        self.params_data['bs'] = bs / num_rows\n",
    "    \n",
    "    def sort_params(self, method = 'll'):\n",
    "        '''sort the parameters according to cost method.'''\n",
    "        if method == 'll':\n",
    "            self.params_data = self.params_data.sort_values(by='ll')\n",
    "        elif method == 'wp':\n",
    "            self.params_data = self.params_data.sort_values(by='wp', ascending = False)\n",
    "        else:\n",
    "            self.params_data = self.params_data.sort_values(by='bs')\n",
    "    \n",
    "    def update_select_ratings(self, year, a_params):\n",
    "        '''this function updates only the ratings corresponding to the given\n",
    "        parameters. It takes the average probability.'''\n",
    "        \n",
    "        # first reset the ratings.\n",
    "        n = len(self.k_params)\n",
    "        self.select_ratings = {player: (0, np.ones((n,3))) for player in self.players}\n",
    "        \n",
    "        ll = 0\n",
    "        wp = 0\n",
    "        bs = 0\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            for j, row in self.data[i].iterrows():\n",
    "                \n",
    "                winner = row['winner_name']\n",
    "                loser = row['loser_name']\n",
    "                surface = row['surface']\n",
    "                if surface == 'Clay':\n",
    "                    s = np.array([1,0,0])\n",
    "                elif surface == 'Hard':\n",
    "                    s = np.array([0,0,1])\n",
    "                else: # Carpet gets classified as Grass.\n",
    "                    s = np.array([0,1,0])\n",
    "                \n",
    "                \n",
    "                # get ratings.\n",
    "                wnm, wrating = self.select_ratings[winner]\n",
    "                lnm, lrating = self.select_ratings[loser]\n",
    "                \n",
    "                # update.\n",
    "                prob, u1, u2 = self.update_one(wrating, lrating, wnm, lnm, \n",
    "                                               self.k_params, a_params, s)\n",
    "                self.select_ratings[winner] = wnm + 1, wrating + u1\n",
    "                self.select_ratings[loser] = lnm + 1, lrating + u2\n",
    "                \n",
    "                # what's the prob?\n",
    "                prob = np.mean(prob)\n",
    "                \n",
    "                # compute log-loss error or win prediction percentage.\n",
    "                if(i + self.start_year >= year):\n",
    "                    ll -= np.log(prob)\n",
    "                    wp += (prob > 0.5).astype(float)\n",
    "                    bs += (1-prob)**2\n",
    "        \n",
    "        # figure out what to divide cost by.\n",
    "        num_rows = 0\n",
    "        for i in range(min(len(self.data), self.end_year + 1 - year)):\n",
    "            num_rows += len(self.data[year - self.start_year - 1 + i])\n",
    "\n",
    "        return (ll / num_rows, wp / num_rows, bs / num_rows)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ll        wp        bs\n",
      "6582  0.575501  0.678254  0.197409\n",
      "8772  0.575569  0.679325  0.197355\n",
      "4473  0.575620  0.679489  0.197426\n",
      "3921  0.575660  0.679572  0.197463\n",
      "10    0.575678  0.679489  0.197462\n"
     ]
    }
   ],
   "source": [
    "elo_sdkf = Elo_sdkf(2000, 2013, 10000)\n",
    "elo_sdkf.update_all_ratings(2010)\n",
    "elo_sdkf.sort_params()\n",
    "df = elo_sdkf.get_params_data()\n",
    "print(df[['ll','wp','bs']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            a1        a2        a3        a4        a5        a6        a7  \\\n",
      "6582  1.497282  0.709504  0.223734  0.035879  1.016345  0.891814  0.635505   \n",
      "8772  1.496927  0.122563  0.659796  0.035299  0.704547  1.405535  0.895188   \n",
      "4473  1.403872  0.472810  0.730792  0.233342  0.614701  1.108361  0.540628   \n",
      "3921  1.459754  0.449260  0.745738  0.556220  1.398105  0.590583  0.627694   \n",
      "10    1.459020  0.305191  0.589823  0.331715  1.321166  0.879316  0.332806   \n",
      "\n",
      "            a8        a9  \n",
      "6582  1.089314  1.143836  \n",
      "8772  0.967678  1.212636  \n",
      "4473  1.486120  1.129831  \n",
      "3921  0.869944  1.246126  \n",
      "10    0.439226  1.318882  \n"
     ]
    }
   ],
   "source": [
    "col_names = ['a'+str(i) for i in range(1,10)]\n",
    "print(df[col_names].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are so many parameters now, uniform distribution gets sparser. Let's tighten up our range by taking the top 50 parameters and setting the uniform distribution to be around their means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.30804042 0.42005384 0.57899851 0.27871053 0.94740469 0.88936044\n",
      " 0.58987385 0.93457748 1.20006381]\n",
      "[0.01910083 0.11820104 0.05413589 0.04091668 0.1067347  0.10136307\n",
      " 0.04194059 0.09898853 0.02578975]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array(df[col_names].iloc[:50]), axis=0))\n",
    "print(np.var(np.array(df[col_names].iloc[:50]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.mean(np.array(df[col_names].iloc[:50]), axis=0) - 4*np.var(np.array(df[col_names].iloc[:50]), axis=0)\n",
    "upper = np.mean(np.array(df[col_names].iloc[:50]), axis=0) + 4*np.var(np.array(df[col_names].iloc[:50]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_sdkf = Elo_sdkf(1995, 2013, 10000, lower=lower, upper=upper)\n",
    "elo_sdkf.update_all_ratings(2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ll        wp        bs\n",
      "3746  0.574072  0.679654  0.196739\n",
      "6182  0.574075  0.680478  0.196746\n",
      "1213  0.574086  0.680313  0.196760\n",
      "425   0.574098  0.680560  0.196769\n",
      "584   0.574109  0.681054  0.196764\n",
      "            ll        wp        bs\n",
      "624   0.574792  0.682867  0.197084\n",
      "1489  0.575063  0.682784  0.197146\n",
      "3537  0.574289  0.682702  0.196845\n",
      "3341  0.574374  0.682702  0.196876\n",
      "7902  0.574644  0.682619  0.196957\n",
      "            ll        wp        bs\n",
      "3746  0.574072  0.679654  0.196739\n",
      "6182  0.574075  0.680478  0.196746\n",
      "4921  0.574123  0.678336  0.196752\n",
      "1213  0.574086  0.680313  0.196760\n",
      "584   0.574109  0.681054  0.196764\n"
     ]
    }
   ],
   "source": [
    "elo_sdkf.sort_params()\n",
    "df = elo_sdkf.get_params_data()\n",
    "print(df[['ll','wp','bs']].head())\n",
    "elo_sdkf.sort_params(method = 'wp')\n",
    "df = elo_sdkf.get_params_data()\n",
    "print(df[['ll','wp','bs']].head())\n",
    "elo_sdkf.sort_params(method = 'bs')\n",
    "df = elo_sdkf.get_params_data()\n",
    "print(df[['ll','wp','bs']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            a1        a2        a3        a4        a5        a6        a7  \\\n",
      "3746  1.383559  0.186148  0.582325  0.163048  1.366782  0.642451  0.640518   \n",
      "6182  1.367565 -0.038163  0.501433  0.141208  1.225584  0.738717  0.557209   \n",
      "4921  1.367434  0.034490  0.492734  0.135281  0.840048  0.683265  0.598902   \n",
      "1213  1.347424  0.120422  0.612078  0.116368  1.020613  0.703088  0.524921   \n",
      "584   1.373804  0.209944  0.514236  0.163280  1.325427  0.585647  0.450906   \n",
      "\n",
      "            a8        a9  \n",
      "3746  1.258164  1.285806  \n",
      "6182  0.815735  1.200875  \n",
      "4921  1.250441  1.270224  \n",
      "1213  1.242716  1.166514  \n",
      "584   0.925887  1.271030  \n"
     ]
    }
   ],
   "source": [
    "col_names = ['a'+str(i) for i in range(1,10)]\n",
    "print(df[col_names].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5792334709883984, 0.673233695652174, 0.19887088255743884)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_params = np.array(df[col_names].iloc[:50])\n",
    "elo_sdkf = Elo_sdkf(1980, 2014, 1)\n",
    "elo_sdkf.update_select_ratings(2014, a_params = a_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.38355895,  0.18614784,  0.58232495,  0.16304785,  1.36678152,\n",
       "         0.6424513 ,  0.64051841,  1.25816376,  1.28580581],\n",
       "       [ 1.3675646 , -0.03816339,  0.50143259,  0.14120843,  1.22558376,\n",
       "         0.73871681,  0.5572088 ,  0.81573485,  1.20087467],\n",
       "       [ 1.3674336 ,  0.03449045,  0.49273421,  0.13528091,  0.84004762,\n",
       "         0.68326467,  0.59890153,  1.25044115,  1.2702242 ],\n",
       "       [ 1.34742374,  0.12042227,  0.61207821,  0.11636838,  1.02061274,\n",
       "         0.70308823,  0.52492127,  1.24271577,  1.16651379],\n",
       "       [ 1.37380444,  0.20994372,  0.51423607,  0.16327988,  1.32542685,\n",
       "         0.58564659,  0.45090589,  0.92588663,  1.27102954],\n",
       "       [ 1.34748103,  0.10105228,  0.44034158,  0.1387066 ,  0.99520008,\n",
       "         0.67828855,  0.51300676,  1.21462154,  1.26050307],\n",
       "       [ 1.33221687, -0.04874868,  0.55306821,  0.12238943,  1.31506376,\n",
       "         0.59028718,  0.43069407,  0.83557575,  1.18334558],\n",
       "       [ 1.34757652, -0.04455222,  0.46752248,  0.13306174,  1.30208243,\n",
       "         0.77035417,  0.67960555,  0.907524  ,  1.29175289],\n",
       "       [ 1.37429308,  0.08719614,  0.68191197,  0.1457002 ,  1.11726643,\n",
       "         0.73458162,  0.43279596,  1.06036027,  1.28988404],\n",
       "       [ 1.35789679,  0.11368444,  0.55074404,  0.17608501,  0.99298528,\n",
       "         0.78520433,  0.53413864,  0.90708815,  1.17203591],\n",
       "       [ 1.3228672 ,  0.22460394,  0.59115955,  0.16251838,  1.35929149,\n",
       "         0.7832207 ,  0.50493932,  1.00876182,  1.23129222],\n",
       "       [ 1.33956932,  0.0239962 ,  0.58393477,  0.15779203,  1.0593802 ,\n",
       "         0.86732857,  0.60253669,  1.26701162,  1.18362211],\n",
       "       [ 1.3475189 ,  0.1508845 ,  0.6866842 ,  0.15154933,  1.37290801,\n",
       "         0.76052089,  0.53172232,  1.12817034,  1.18164184],\n",
       "       [ 1.35978464,  0.35391411,  0.48226789,  0.13605689,  1.37035217,\n",
       "         0.73686065,  0.60300746,  1.06775354,  1.1548755 ],\n",
       "       [ 1.37747105,  0.18210879,  0.63162115,  0.11873486,  1.33664072,\n",
       "         1.08708562,  0.60030109,  1.21518059,  1.24135859],\n",
       "       [ 1.35810107,  0.27647725,  0.40891151,  0.15831014,  1.18255958,\n",
       "         0.69596317,  0.57044947,  1.13098124,  1.2476656 ],\n",
       "       [ 1.30750431,  0.02996135,  0.50632721,  0.11524257,  1.11664255,\n",
       "         0.66745013,  0.43232889,  0.87618514,  1.16877066],\n",
       "       [ 1.29588756,  0.02416756,  0.48746917,  0.18000678,  1.15137023,\n",
       "         0.7728682 ,  0.53121034,  1.16908943,  1.25701209],\n",
       "       [ 1.3529068 ,  0.05054963,  0.51258594,  0.17472522,  1.04951615,\n",
       "         0.7311963 ,  0.46370711,  0.86235726,  1.30237638],\n",
       "       [ 1.31190193,  0.08985683,  0.60440876,  0.15922898,  1.19260006,\n",
       "         0.6181196 ,  0.48644647,  1.1637268 ,  1.29384056],\n",
       "       [ 1.37787564,  0.02281227,  0.63807072,  0.11530653,  0.85423638,\n",
       "         1.05625346,  0.51141274,  1.04632422,  1.3000833 ],\n",
       "       [ 1.37151117,  0.33658006,  0.54388336,  0.12145963,  1.01543561,\n",
       "         0.72067512,  0.68304626,  0.99615998,  1.29541739],\n",
       "       [ 1.35218477,  0.10003519,  0.56883812,  0.20776226,  1.00528063,\n",
       "         0.92619931,  0.52137068,  1.14960561,  1.23381356],\n",
       "       [ 1.28931289, -0.04292619,  0.46211883,  0.15646407,  1.19815194,\n",
       "         0.6437496 ,  0.49240967,  1.04220005,  1.1928423 ],\n",
       "       [ 1.37125674,  0.12177755,  0.48045848,  0.13234455,  1.00428119,\n",
       "         1.03700146,  0.5012671 ,  0.8971163 ,  1.20842644],\n",
       "       [ 1.36507042, -0.02674074,  0.53760619,  0.23935899,  1.04090761,\n",
       "         0.67524865,  0.57605204,  1.26738358,  1.19018269],\n",
       "       [ 1.32998657,  0.06090011,  0.58992807,  0.17906594,  1.22257306,\n",
       "         0.9559039 ,  0.56957759,  1.26154074,  1.24332888],\n",
       "       [ 1.35280548,  0.19931858,  0.55823074,  0.16587527,  1.16725237,\n",
       "         0.82742968,  0.57834717,  1.0442035 ,  1.1156792 ],\n",
       "       [ 1.36239255,  0.01399354,  0.48923124,  0.11670662,  0.65743237,\n",
       "         0.73966126,  0.63753008,  0.991504  ,  1.25814764],\n",
       "       [ 1.36132977, -0.027191  ,  0.49532066,  0.22841522,  1.30551735,\n",
       "         0.54787325,  0.47304143,  1.23884131,  1.21617181],\n",
       "       [ 1.31502705, -0.02468423,  0.52123586,  0.23125486,  1.33202832,\n",
       "         0.79533247,  0.5056045 ,  1.04727507,  1.1697835 ],\n",
       "       [ 1.36623251,  0.18104351,  0.58269522,  0.12947109,  1.18804818,\n",
       "         1.07615949,  0.52134641,  0.89604297,  1.269627  ],\n",
       "       [ 1.36815151,  0.19236386,  0.52783123,  0.14466369,  1.04213172,\n",
       "         1.03815541,  0.61871307,  1.06792022,  1.19155958],\n",
       "       [ 1.3465604 ,  0.1307275 ,  0.46155348,  0.12219405,  1.12732372,\n",
       "         1.0277624 ,  0.50754384,  1.29024188,  1.28136484],\n",
       "       [ 1.31490788,  0.04088168,  0.54595279,  0.19167601,  1.34130933,\n",
       "         0.83738042,  0.43703085,  1.06941058,  1.15277464],\n",
       "       [ 1.33238618,  0.04532485,  0.57193783,  0.12134334,  0.92385526,\n",
       "         0.53133367,  0.59433928,  1.27930676,  1.21705627],\n",
       "       [ 1.38236483,  0.07796408,  0.40733865,  0.16360769,  1.26821586,\n",
       "         0.80864275,  0.66762259,  1.19710486,  1.18163443],\n",
       "       [ 1.28641695,  0.05079405,  0.60065085,  0.14699339,  1.33430034,\n",
       "         0.77575381,  0.63758617,  1.27914249,  1.28024068],\n",
       "       [ 1.3743938 , -0.04971969,  0.5473691 ,  0.23559192,  0.93358768,\n",
       "         0.79212018,  0.4553448 ,  1.13515381,  1.1423703 ],\n",
       "       [ 1.3807826 ,  0.30197951,  0.52347434,  0.13861728,  1.264575  ,\n",
       "         0.74651998,  0.5959744 ,  0.86434117,  1.11522856],\n",
       "       [ 1.34409159,  0.16841553,  0.64214438,  0.15153745,  1.11634826,\n",
       "         0.84849004,  0.47411629,  1.25798744,  1.25123813],\n",
       "       [ 1.29287385, -0.02720172,  0.5190945 ,  0.20735084,  1.22119168,\n",
       "         0.69309277,  0.50928114,  1.07192009,  1.16849679],\n",
       "       [ 1.27591778,  0.08773436,  0.49459884,  0.13539913,  1.27743189,\n",
       "         0.73766474,  0.62801992,  1.31001136,  1.2459732 ],\n",
       "       [ 1.35077345,  0.26238724,  0.4772878 ,  0.1312569 ,  1.12925137,\n",
       "         0.94318257,  0.64610704,  1.15226737,  1.19758783],\n",
       "       [ 1.35531393,  0.26590195,  0.50313372,  0.18515477,  1.14865226,\n",
       "         0.63489735,  0.64475502,  1.26886529,  1.22571783],\n",
       "       [ 1.35153997,  0.00824424,  0.52006587,  0.21393875,  1.03143279,\n",
       "         0.54548269,  0.50452004,  1.23637878,  1.2245652 ],\n",
       "       [ 1.38036553,  0.08589139,  0.47029133,  0.20692721,  1.1883251 ,\n",
       "         0.85069859,  0.44958677,  1.2553418 ,  1.13021467],\n",
       "       [ 1.3273346 ,  0.14128421,  0.57947671,  0.14288925,  1.10059907,\n",
       "         0.56139913,  0.48564791,  0.9783682 ,  1.11714242],\n",
       "       [ 1.34929756,  0.36434793,  0.53176848,  0.20975789,  1.32936367,\n",
       "         0.68355393,  0.56683019,  1.16216072,  1.23846384],\n",
       "       [ 1.36501415,  0.41072791,  0.56026327,  0.15035004,  1.33543483,\n",
       "         0.82451592,  0.54761785,  1.10372175,  1.13092373]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on 2015-2019 data\n",
    "Recall the 2015-2019 comparison between the randomly initialized Elo model and the FiveThirtyEight Elo model:\n",
    "```\n",
    "  optimized_for        ll        wp        bs\n",
    "0            ll  0.607112  0.658860  0.209942\n",
    "1            wp  0.623405  0.657555  0.214121\n",
    "2            bs  0.607411  0.658723  0.209912\n",
    "3           538  0.611903  0.661607  0.210791\n",
    "```\n",
    "\n",
    "Let's try our SDKF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6031931424789028, 0.663804945054945, 0.20829817411371923)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo_sdkf = Elo_sdkf(1980, 2019, 1)\n",
    "elo_sdkf.update_select_ratings(2015, a_params = a_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we made a pretty significant improvement in log-loss error over FiveThirtyEight's model, while eliminating hand-picking of hyperparameters as much as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with SA+SO average: BUMMER\n",
    "Now let's build a model in which the win probability is averaged between the predictions given by the surface-agnostic rating and the surface-only rating. With our framework, the respective $A$s are $$ \\begin{pmatrix} 1&1&1\\\\1&1&1\\\\1&1&1\\end{pmatrix}, \\quad \\begin{pmatrix}1&0&0\\\\0&1&0\\\\0&0&1\\end{pmatrix}.$$ The average method fits right into our framework and can be computed with one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6026983365860035, 0.6609203296703297, 0.20832241189833223)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo_avg = Elo_sdkf(1980,2019,1)\n",
    "elo_avg.update_select_ratings(2015, a_params = np.array([\n",
    "    np.ones(9),\n",
    "    np.array([1,0,0,0,1,0,0,0,1])\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shoot, this is as good as mine, and a lot simpler..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Well, this is a bit of a bummer for me since this model almost identically to mine, and its parameters are a lot simpler. But this model still uses my hyperparameter principles from the previous notebook, and it fits quite nicely into the mathematical framework I've made here. If I could search for parameters like a thousand times faster, I might try to optimize for a weighted average of probabilities from two matrices, to get results like the above. With our current parameter search, we can't find this local min because neither matrix by itself does well, but averaged together they do well. Doing this larger parameter search, we'd need to search through, in all probably, ten million parameters or so... which doesn't seem all that bad, in the context of all the deep learning stuff I'm doing recently. So next up, I'm going to load this up in Google Colab and see if I can run it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
